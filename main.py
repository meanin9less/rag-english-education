import google.generativeai as genai
import os
import time
import json
import re
from dotenv import load_dotenv
from models import (DatabaseConfig, DatabaseManager, User, ChatHistory, 
                   GrammarCategory, GrammarTopic, GrammarAchievement, 
                   ReadingType, VocabularyCategory, VocabularyAchievement, Word,
                   ContentGenerationRequest, QuestionDistribution)

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# ì œë¯¸ë‚˜ì´ API í‚¤ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
genai.configure(api_key=os.getenv('GEMINI_API_KEY'))

# ì œë¯¸ë‚˜ì´ ëª¨ë¸ ìƒì„±
model = genai.GenerativeModel('gemini-2.5-pro')

# í”„ë¡¬í”„íŠ¸ëŠ” prompts.py íŒŒì¼ì—ì„œ ê´€ë¦¬
from prompts import get_prompt, format_prompt

def generate_response(prompt):
    """ì œë¯¸ë‚˜ì´ ëª¨ë¸ì„ ì‚¬ìš©í•´ ì‘ë‹µ ìƒì„±"""
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

def generate_content_with_prompt(prompt_type, **kwargs):
    """
    í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì‚¬ìš©í•´ ì½˜í…ì¸  ìƒì„±
    
    Args:
        prompt_type: í”„ë¡¬í”„íŠ¸ ìœ í˜• ("passage", "question", "answer")
        **kwargs: í”„ë¡¬í”„íŠ¸ì— ì±„ìš¸ íŒŒë¼ë¯¸í„°ë“¤
    
    Returns:
        str: ìƒì„±ëœ ì‘ë‹µ
    """
    try:
        # í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ…
        formatted_prompt = format_prompt(prompt_type, **kwargs)
        
        # ì‘ë‹µ ìƒì„±
        response = generate_response(formatted_prompt)
        return response
    except Exception as e:
        print(f"ì½˜í…ì¸  ìƒì„± ì˜¤ë¥˜: {e}")
        return None

# ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
def setup_database():
    """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì •"""
    config = DatabaseConfig(
        host=os.getenv('DB_HOST', 'localhost'),
        port=int(os.getenv('DB_PORT', 5432)),
        database=os.getenv('DB_NAME', ''),
        username=os.getenv('DB_USER', ''),
        password=os.getenv('DB_PASSWORD', '')
    )
    
    db_manager = DatabaseManager(config)
    if db_manager.connect():
        print("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ")
        db_manager.create_tables()
        return db_manager
    else:
        print("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
        return None

# SQLAlchemy CRUD í•¨ìˆ˜ë“¤
def create_user(db_manager, username, email):
    """ì‚¬ìš©ì ìƒì„±"""
    session = db_manager.get_session()
    try:
        new_user = User(username=username, email=email)
        session.add(new_user)
        session.commit()
        print(f"ì‚¬ìš©ì ìƒì„±: {username}")
        return new_user.id
    except Exception as e:
        session.rollback()
        print(f"ì‚¬ìš©ì ìƒì„± ì˜¤ë¥˜: {e}")
        return None
    finally:
        session.close()

def get_user_by_id(db_manager, user_id):
    """IDë¡œ ì‚¬ìš©ì ì¡°íšŒ"""
    session = db_manager.get_session()
    try:
        user = session.query(User).filter(User.id == user_id).first()
        return user
    finally:
        session.close()

def save_chat_history(db_manager, user_id, prompt, response):
    """ì±„íŒ… ê¸°ë¡ ì €ì¥"""
    session = db_manager.get_session()
    try:
        chat = ChatHistory(user_id=user_id, prompt=prompt, response=response)
        session.add(chat)
        session.commit()
        print("ì±„íŒ… ê¸°ë¡ ì €ì¥ë¨")
        return chat.id
    except Exception as e:
        session.rollback()
        print(f"ì±„íŒ… ê¸°ë¡ ì €ì¥ ì˜¤ë¥˜: {e}")
        return None
    finally:
        session.close()

def get_chat_history(db_manager, user_id=None, limit=10):
    """ì±„íŒ… ê¸°ë¡ ì¡°íšŒ"""
    session = db_manager.get_session()
    try:
        query = session.query(ChatHistory)
        if user_id:
            query = query.filter(ChatHistory.user_id == user_id)
        chats = query.order_by(ChatHistory.created_at.desc()).limit(limit).all()
        return chats
    finally:
        session.close()

# ë°ì´í„° ì¡°íšŒ í•¨ìˆ˜ë“¤
def get_grammar_categories(db_manager):
    """ë¬¸ë²• ì¹´í…Œê³ ë¦¬ ì¡°íšŒ"""
    session = db_manager.get_session()
    try:
        categories = session.query(GrammarCategory).order_by(GrammarCategory.order_num).all()
        return categories
    finally:
        session.close()

def get_grammar_topics_by_category(db_manager, category_id):
    """ì¹´í…Œê³ ë¦¬ë³„ ë¬¸ë²• ì£¼ì œ ì¡°íšŒ"""
    session = db_manager.get_session()
    try:
        topics = session.query(GrammarTopic).filter(
            GrammarTopic.category_id == category_id
        ).order_by(GrammarTopic.order_num).all()
        return topics
    finally:
        session.close()

def get_achievements_by_topic(db_manager, topic_id):
    """ì£¼ì œë³„ ì„±ì·¨ê¸°ì¤€ ì¡°íšŒ"""
    session = db_manager.get_session()
    try:
        achievements = session.query(GrammarAchievement).filter(
            GrammarAchievement.topic_id == topic_id
        ).all()
        return achievements
    finally:
        session.close()

def get_reading_types(db_manager):
    """ë…í•´ ìœ í˜• ì¡°íšŒ"""
    session = db_manager.get_session()
    try:
        reading_types = session.query(ReadingType).order_by(ReadingType.order_num).all()
        return reading_types
    finally:
        session.close()

def get_vocabulary_categories(db_manager):
    """ì–´íœ˜ ì¹´í…Œê³ ë¦¬ ì¡°íšŒ"""
    session = db_manager.get_session()
    try:
        categories = session.query(VocabularyCategory).order_by(VocabularyCategory.order_num).all()
        return categories
    finally:
        session.close()

def get_vocabulary_achievements_by_category(db_manager, category_id):
    """ì¹´í…Œê³ ë¦¬ë³„ ì–´íœ˜ ì„±ì·¨ê¸°ì¤€ ì¡°íšŒ"""
    session = db_manager.get_session()
    try:
        achievements = session.query(VocabularyAchievement).filter(
            VocabularyAchievement.category_id == category_id
        ).all()
        return achievements
    finally:
        session.close()

def get_words_by_level(db_manager, level):
    """ë ˆë²¨ë³„ ë‹¨ì–´ ì¡°íšŒ"""
    session = db_manager.get_session()
    try:
        words = session.query(Word).filter(Word.level == level).all()
        return [word.word for word in words]
    finally:
        session.close()

def calculate_question_distribution(request: ContentGenerationRequest):
    """ë¬¸í•­ ìˆ˜ ê³„ì‚° ë° ë¶„ë°°"""
    distributions = []
    
    # 1. ì¹´í…Œê³ ë¦¬ë³„ ê¸°ë³¸ ë¬¸í•­ ìˆ˜ ê³„ì‚°
    total_ratio = sum(cat.ratio for cat in request.categories)
    
    for category in request.categories:
        # ì¹´í…Œê³ ë¦¬ë³„ ë¬¸í•­ ìˆ˜
        category_questions = int(request.total_questions * category.ratio / total_ratio)
        
        # ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ë³„ ë¬¸í•­ ìˆ˜ (ê· ë“± ë¶„ë°°)
        subcategory_questions = category_questions // len(category.subcategories)
        remaining = category_questions % len(category.subcategories)
        
        for i, subcategory in enumerate(category.subcategories):
            # ë‚˜ë¨¸ì§€ëŠ” ì•ìª½ ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ì— ë°°ë¶„
            questions_for_subcategory = subcategory_questions + (1 if i < remaining else 0)
            
            # ë‚œì´ë„ë³„ ë¶„ë°°
            if request.difficulty == "ë¶„ë°°":
                high_count = max(1, int(questions_for_subcategory * request.difficulty_distribution.high / 100))
                low_count = max(1, int(questions_for_subcategory * request.difficulty_distribution.low / 100))
                medium_count = questions_for_subcategory - high_count - low_count
                
                # ê° ë‚œì´ë„ë³„ë¡œ QuestionDistribution ìƒì„±
                if high_count > 0:
                    distributions.append(QuestionDistribution(category.name, subcategory, high_count, "ìƒ"))
                if medium_count > 0:
                    distributions.append(QuestionDistribution(category.name, subcategory, medium_count, "ì¤‘"))
                if low_count > 0:
                    distributions.append(QuestionDistribution(category.name, subcategory, low_count, "í•˜"))
            else:
                # ë‹¨ì¼ ë‚œì´ë„
                distributions.append(QuestionDistribution(category.name, subcategory, questions_for_subcategory, request.difficulty))
    
    return distributions

def print_question_distribution(distributions):
    """ë¬¸ì œ ë¶„ë°° ê²°ê³¼ ì¶œë ¥"""
    print("\nğŸ“Š ë¬¸ì œ ë¶„ë°° ê³„íš:")
    print("=" * 50)
    
    category_totals = {}
    difficulty_totals = {"ìƒ": 0, "ì¤‘": 0, "í•˜": 0}
    
    for dist in distributions:
        # ì¹´í…Œê³ ë¦¬ë³„ ì§‘ê³„
        if dist.category not in category_totals:
            category_totals[dist.category] = 0
        category_totals[dist.category] += dist.count
        
        # ë‚œì´ë„ë³„ ì§‘ê³„
        if dist.difficulty_level in difficulty_totals:
            difficulty_totals[dist.difficulty_level] += dist.count
        
        print(f"  {dist.category} > {dist.subcategory} ({dist.difficulty_level}): {dist.count}ë¬¸í•­")
    
    print("\nğŸ“‹ ì¹´í…Œê³ ë¦¬ë³„ ìš”ì•½:")
    for category, count in category_totals.items():
        print(f"  {category}: {count}ë¬¸í•­")
    
    print("\nğŸ¯ ë‚œì´ë„ë³„ ìš”ì•½:")
    for difficulty, count in difficulty_totals.items():
        if count > 0:
            print(f"  {difficulty}: {count}ë¬¸í•­")
    
    total = sum(dist.count for dist in distributions)
    print(f"\nğŸ“ ì´ ë¬¸í•­ ìˆ˜: {total}ë¬¸í•­")
    print("=" * 50)

def process_user_request_new(db_manager, request_data):
    """
    ìƒˆë¡œìš´ êµ¬ì¡°ì˜ ì‚¬ìš©ì ìš”ì²­ì„ ì²˜ë¦¬í•˜ì—¬ ì˜ì–´ í•™ìŠµ ì½˜í…ì¸ ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        db_manager: ë°ì´í„°ë² ì´ìŠ¤ ë§¤ë‹ˆì €
        request_data: ContentGenerationRequest ê°ì²´ ë˜ëŠ” ë”•ì…”ë„ˆë¦¬
    
    Returns:
        dict: ìƒì„±ëœ ì½˜í…ì¸  (ì§€ë¬¸, ì˜ˆë¬¸, ë¬¸ì œ, ë‹µì•ˆ)
    """
    # ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° ê°ì²´ë¡œ ë³€í™˜
    if isinstance(request_data, dict):
        request = ContentGenerationRequest(**request_data)
    else:
        request = request_data
    
    print(f"========== ìƒˆë¡œìš´ êµ¬ì¡° ì‚¬ìš©ì ìš”ì²­ ì²˜ë¦¬ ì‹œì‘ ==========")
    print(f"í•™ë…„: {request.grade}í•™ë…„")
    print(f"ë¬¸ì œ ìœ í˜•: {request.question_type}")
    print(f"ë‚œì´ë„: {request.difficulty}")
    print(f"ì´ ë¬¸í•­ ìˆ˜: {request.total_questions}")
    
    print(f"\nì¹´í…Œê³ ë¦¬ êµ¬ì„±:")
    for cat in request.categories:
        print(f"  - {cat.name} ({cat.ratio}%): {', '.join(cat.subcategories)}")
    
    # 1. ë¬¸í•­ ë¶„ë°° ê³„ì‚°
    distributions = calculate_question_distribution(request)
    print_question_distribution(distributions)
    
    # 2. ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì •ë³´ ì¡°íšŒ
    db_info = gather_db_info_new(db_manager, request)
    
    # 3. ë¶„ë°°ë³„ë¡œ ì½˜í…ì¸  ìƒì„±
    all_results = generate_content_by_distribution(db_manager, request, distributions, db_info)
    
    return all_results

def process_user_request(db_manager, grade, categories, difficulty, grammar_subcategories=None):
    """
    ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ í•¨ìˆ˜ (ë ˆê±°ì‹œ ì§€ì›)
    """
    print(f"========== ê¸°ì¡´ êµ¬ì¡° ì‚¬ìš©ì ìš”ì²­ ì²˜ë¦¬ ì‹œì‘ ==========")
    print(f"í•™ë…„: {grade}")
    print(f"ì¹´í…Œê³ ë¦¬: {categories}")
    print(f"ë‚œì´ë„: {difficulty}")
    if grammar_subcategories:
        print(f"ë¬¸ë²• ì†Œë¶„ë¥˜: {grammar_subcategories}")
    
    # 1. ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì •ë³´ ì¡°íšŒ
    db_info = gather_db_info(db_manager, categories, difficulty, grammar_subcategories)
    
    # 2. í”„ë¡¬í”„íŠ¸ ë§¤ê°œë³€ìˆ˜ ìƒì„±
    prompt_params = build_prompt_params(grade, categories, difficulty, db_info)
    
    # 3. ì½˜í…ì¸  ìƒì„±
    result = generate_learning_content(prompt_params)
    
    return result

def gather_db_info(db_manager, categories, difficulty, grammar_subcategories=None):
    """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ í•„ìš”í•œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
    db_info = {
        'grammar_points': [],
        'reading_types': [],
        'vocabulary_info': [],
        'word_list': []
    }
    
    # ë‚œì´ë„ì— ë”°ë¥¸ ì–´íœ˜ ë ˆë²¨ ë§¤í•‘
    level_mapping = {
        "ê¸°ë³¸": "basic",
        "ì¤‘ê°„": "middle", 
        "ê³ ê¸‰": "high"
    }
    word_level = level_mapping.get(difficulty, "basic")
    
    # ë‹¨ì–´ ëª©ë¡ ì¡°íšŒ
    db_info['word_list'] = get_words_by_level(db_manager, word_level)[:20]  # ìƒìœ„ 20ê°œë§Œ
    
    for category in categories:
        if category == "ë¬¸ë²•":
            if grammar_subcategories:
                # íŠ¹ì • ë¬¸ë²• ì†Œë¶„ë¥˜ê°€ ì§€ì •ëœ ê²½ìš°
                for subcategory in grammar_subcategories:
                    # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” subcategory ì´ë¦„ìœ¼ë¡œ DB ì¡°íšŒ
                    db_info['grammar_points'].append(subcategory)
            else:
                # ì „ì²´ ë¬¸ë²• ì¹´í…Œê³ ë¦¬ì—ì„œ ëœë¤ ì„ íƒ
                grammar_categories = get_grammar_categories(db_manager)
                if grammar_categories:
                    # ì²« ë²ˆì§¸ ì¹´í…Œê³ ë¦¬ì˜ ì£¼ì œë“¤ ì¡°íšŒ
                    topics = get_grammar_topics_by_category(db_manager, grammar_categories[0].id)
                    if topics:
                        db_info['grammar_points'].append(topics[0].name)
        
        elif category == "ë…í•´":
            reading_types = get_reading_types(db_manager)
            if reading_types:
                db_info['reading_types'].extend([rt.name for rt in reading_types[:3]])
        
        elif category == "ì–´íœ˜":
            vocab_categories = get_vocabulary_categories(db_manager)
            if vocab_categories:
                db_info['vocabulary_info'].append(vocab_categories[0].name)
    
    return db_info

def gather_db_info_new(db_manager, request: ContentGenerationRequest):
    """ìƒˆë¡œìš´ êµ¬ì¡°ë¥¼ ìœ„í•œ ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ ìˆ˜ì§‘"""
    db_info = {
        'grammar_points': [],
        'reading_types': [],
        'vocabulary_info': [],
        'word_list': []
    }
    
    # ë‚œì´ë„ì— ë”°ë¥¸ ì–´íœ˜ ë ˆë²¨ ë§¤í•‘
    level_mapping = {
        "ìƒ": "high",
        "ì¤‘": "middle", 
        "í•˜": "basic"
    }
    
    # ê¸°ë³¸ ë‹¨ì–´ ë ˆë²¨ (ë¶„ë°°ì¸ ê²½ìš° ì¤‘ê°„ ë ˆë²¨ ì‚¬ìš©)
    if request.difficulty == "ë¶„ë°°":
        word_level = "middle"
    else:
        word_level = level_mapping.get(request.difficulty, "middle")
    
    # ë‹¨ì–´ ëª©ë¡ ì¡°íšŒ
    db_info['word_list'] = get_words_by_level(db_manager, word_level)[:20]
    
    # ì¹´í…Œê³ ë¦¬ë³„ ì •ë³´ ìˆ˜ì§‘
    for category in request.categories:
        if category.name == "ë¬¸ë²•":
            for subcategory in category.subcategories:
                db_info['grammar_points'].append(subcategory)
        
        elif category.name == "ë…í•´":
            for subcategory in category.subcategories:
                db_info['reading_types'].append(subcategory)
        
        elif category.name == "ì–´íœ˜":
            for subcategory in category.subcategories:
                db_info['vocabulary_info'].append(subcategory)
    
    return db_info

def generate_content_by_distribution(db_manager, request: ContentGenerationRequest, distributions, db_info):
    """ë¶„ë°° ê³„íšì— ë”°ë¼ ì½˜í…ì¸  ìƒì„±"""
    all_results = {
        'passages': [],
        'sentences': [],
        'questions': [],
        'answers': [],
        'distributions': distributions
    }
    
    print(f"\nğŸš€ ë¶„ë°° ê³„íšì— ë”°ë¥¸ ì½˜í…ì¸  ìƒì„± ì‹œì‘")
    
    # ê° ë¶„ë°°ë³„ë¡œ ì½˜í…ì¸  ìƒì„±
    for i, dist in enumerate(distributions):
        print(f"\nğŸ“ [{i+1}/{len(distributions)}] {dist.category} > {dist.subcategory} ({dist.difficulty_level}) - {dist.count}ë¬¸í•­ ìƒì„± ì¤‘...")
        
        # í•´ë‹¹ ë¶„ë°°ì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ ë§¤ê°œë³€ìˆ˜ ìƒì„±
        params = build_prompt_params_for_distribution(request, dist, db_info)
        
        # ì§€ë¬¸ ë° ì˜ˆë¬¸ ìƒì„± (ê° ë¶„ë°°ë§ˆë‹¤ ë³„ë„ ìƒì„±)
        passage_result = generate_content_with_prompt("passage", **params)
        
        if passage_result and "ì˜¤ë¥˜ ë°œìƒ" not in passage_result:
            try:
                json_match = re.search(r'```json\s*(\{.*?\})\s*```', passage_result, re.DOTALL)
                if json_match:
                    passage_data = json.loads(json_match.group(1))
                    
                    # ê²°ê³¼ì— ì¶”ê°€ (ë¶„ë°° ì •ë³´ì™€ í•¨ê»˜)
                    for passage in passage_data.get("passages", []):
                        passage['distribution_info'] = f"{dist.category}-{dist.subcategory}-{dist.difficulty_level}"
                        all_results['passages'].append(passage)
                    
                    for sentence in passage_data.get("sentences", []):
                        sentence['distribution_info'] = f"{dist.category}-{dist.subcategory}-{dist.difficulty_level}"
                        all_results['sentences'].append(sentence)
                    
                    print(f"âœ… ì§€ë¬¸ {len(passage_data.get('passages', []))}ê°œ, ì˜ˆë¬¸ {len(passage_data.get('sentences', []))}ê°œ ìƒì„± ì™„ë£Œ")
                    
            except Exception as e:
                print(f"âŒ ë¶„ë°° {i+1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
    
    # í†µí•©ëœ ë¬¸ì œ ìƒì„± (ëª¨ë“  ì§€ë¬¸ê³¼ ì˜ˆë¬¸ì„ ì‚¬ìš©)
    if all_results['passages'] and all_results['sentences']:
        print(f"\nğŸ” í†µí•© ë¬¸ì œ ìƒì„± ì¤‘... (ì´ {request.total_questions}ë¬¸í•­)")
        questions_result = generate_integrated_questions(request, all_results, db_info)
        if questions_result:
            all_results.update(questions_result)
    
    return all_results

def build_prompt_params_for_distribution(request: ContentGenerationRequest, dist: QuestionDistribution, db_info):
    """íŠ¹ì • ë¶„ë°°ë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ë§¤ê°œë³€ìˆ˜ ìƒì„±"""
    params = {
        "level": f"ì¤‘í•™êµ {request.grade}í•™ë…„",
        "passage_count": "1",  # ë¶„ë°°ë³„ë¡œ 1ê°œì”©
        "passage_length": "80" if dist.difficulty_level == "í•˜" else "100" if dist.difficulty_level == "ì¤‘" else "120",
        "sentence_count": "2",
        "sentence_length": "10" if dist.difficulty_level == "í•˜" else "12" if dist.difficulty_level == "ì¤‘" else "15",
        "word_list": ", ".join(db_info['word_list'][:10]) if db_info['word_list'] else "student, study, school",
        "topic": f"{dist.category} ê´€ë ¨ ì£¼ì œ",
        "grammar_point": dist.subcategory if dist.category == "ë¬¸ë²•" else "ê¸°ë³¸ ë¬¸ë²•",
        "reading_type": dist.subcategory if dist.category == "ë…í•´" else "ë‚´ìš© ì´í•´"
    }
    
    return params

def generate_integrated_questions(request: ContentGenerationRequest, content_results, db_info):
    """í†µí•©ëœ ë¬¸ì œ ë° ë‹µì•ˆ ìƒì„±"""
    # ëª¨ë“  ì§€ë¬¸ê³¼ ì˜ˆë¬¸ì„ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ í†µí•©
    passages_text = "\n\n".join([f"ì§€ë¬¸ {i+1}: {p['title']}\n{p['content']}" 
                                for i, p in enumerate(content_results['passages'])])
    sentences_text = "\n".join([f"ì˜ˆë¬¸ {i+1}: {s['english']}" 
                               for i, s in enumerate(content_results['sentences'])])
    
    question_params = {
        "passages": passages_text,
        "sentences": sentences_text,
        "question_count": str(request.total_questions),
        "question_type": request.question_type,
        "learning_objective": f"ë‹¤ì–‘í•œ ì¹´í…Œê³ ë¦¬ì˜ ì¢…í•©ì  ì´í•´ í‰ê°€"
    }
    
    try:
        # ë¬¸ì œ ìƒì„±
        question_response = generate_content_with_prompt("question", **question_params)
        
        if question_response and "ì˜¤ë¥˜ ë°œìƒ" not in question_response:
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', question_response, re.DOTALL)
            if json_match:
                question_data = json.loads(json_match.group(1))
                questions = question_data.get("questions", [])
                
                if questions:
                    # ë‹µì•ˆ ìƒì„±
                    questions_text = ""
                    for q in questions:
                        questions_text += f"ë¬¸ì œ {q['id']}: {q['question']}\n"
                        if 'modified_passage' in q and q['modified_passage']:
                            questions_text += f"ë³€í˜•ëœ ì§€ë¬¸: {q['modified_passage']}\n"
                        questions_text += "\n".join(q['choices']) + "\n\n"
                    
                    answer_params = {
                        "passages": passages_text,
                        "sentences": sentences_text,
                        "questions": questions_text
                    }
                    
                    answer_response = generate_content_with_prompt("answer", **answer_params)
                    
                    if answer_response and "ì˜¤ë¥˜ ë°œìƒ" not in answer_response:
                        json_match = re.search(r'```json\s*(\{.*?\})\s*```', answer_response, re.DOTALL)
                        if json_match:
                            answer_data = json.loads(json_match.group(1))
                            answers = answer_data.get("answers", [])
                            
                            return {
                                'questions': questions,
                                'answers': answers
                            }
    
    except Exception as e:
        print(f"âŒ í†µí•© ë¬¸ì œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
    
    return {}

def build_prompt_params(grade, categories, difficulty, db_info):
    """í”„ë¡¬í”„íŠ¸ ë§¤ê°œë³€ìˆ˜ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤."""
    
    # ê¸°ë³¸ ë§¤ê°œë³€ìˆ˜
    params = {
        "level": grade,
        "passage_count": "2",
        "passage_length": "80",
        "sentence_count": "3",
        "sentence_length": "12",
        "word_list": ", ".join(db_info['word_list'][:10]) if db_info['word_list'] else "student, study, school",
        "topic": "í•™êµ ìƒí™œê³¼ ì¼ìƒ"
    }
    
    # ì¹´í…Œê³ ë¦¬ë³„ ì •ë³´ ì¶”ê°€
    if "ë¬¸ë²•" in categories and db_info['grammar_points']:
        params["grammar_point"] = db_info['grammar_points'][0]
    else:
        params["grammar_point"] = "í˜„ì¬ì‹œì œì™€ ê³¼ê±°ì‹œì œ"
    
    if "ë…í•´" in categories and db_info['reading_types']:
        params["reading_type"] = ", ".join(db_info['reading_types'])
    else:
        params["reading_type"] = "ì£¼ì œ/ì œëª© ì¶”ë¡ "
    
    # ë‚œì´ë„ë³„ ì¡°ì •
    if difficulty == "ê³ ê¸‰":
        params["passage_length"] = "120"
        params["sentence_length"] = "15"
        params["question_count"] = "4"
    elif difficulty == "ì¤‘ê°„":
        params["passage_length"] = "100"
        params["sentence_length"] = "13"
        params["question_count"] = "3"
    else:  # ê¸°ë³¸
        params["passage_length"] = "80"
        params["sentence_length"] = "12"
        params["question_count"] = "2"
    
    return params

def generate_learning_content(params):
    """í”„ë¡¬í”„íŠ¸ ë§¤ê°œë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ ì½˜í…ì¸ ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    result = {}
    
    try:
        # 1. ì§€ë¬¸ ë° ì˜ˆë¬¸ ìƒì„±
        print("\n========== ì§€ë¬¸ ë° ì˜ˆë¬¸ ìƒì„± ì¤‘ ==========")
        passage_response = generate_content_with_prompt("passage", **params)
        
        if passage_response and "ì˜¤ë¥˜ ë°œìƒ" not in passage_response:
            # JSON íŒŒì‹±
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', passage_response, re.DOTALL)
            if json_match:
                passage_data = json.loads(json_match.group(1))
                result['passages'] = passage_data.get("passages", [])
                result['sentences'] = passage_data.get("sentences", [])
                
                # 2. ë¬¸ì œ ìƒì„±
                print("========== ë¬¸ì œ ìƒì„± ì¤‘ ==========")
                passages_text = "\n\n".join([f"ì§€ë¬¸ {i+1}: {p['title']}\n{p['content']}" 
                                           for i, p in enumerate(result['passages'])])
                sentences_text = "\n".join([f"ì˜ˆë¬¸ {i+1}: {s['english']}" 
                                          for i, s in enumerate(result['sentences'])])
                
                question_params = {
                    "passages": passages_text,
                    "sentences": sentences_text,
                    "question_count": params.get("question_count", "3"),
                    "question_type": "ê°ê´€ì‹ 4ì§€ì„ ë‹¤",
                    "learning_objective": f"{params.get('reading_type', 'ë…í•´')} ë° {params.get('grammar_point', 'ë¬¸ë²•')} ì´í•´ í‰ê°€"
                }
                
                question_response = generate_content_with_prompt("question", **question_params)
                
                if question_response and "ì˜¤ë¥˜ ë°œìƒ" not in question_response:
                    json_match = re.search(r'```json\s*(\{.*?\})\s*```', question_response, re.DOTALL)
                    if json_match:
                        question_data = json.loads(json_match.group(1))
                        result['questions'] = question_data.get("questions", [])
                        
                        # 3. ë‹µì•ˆ ìƒì„±
                        print("========== ë‹µì•ˆ ìƒì„± ì¤‘ ==========")
                        questions_text = ""
                        for q in result['questions']:
                            questions_text += f"ë¬¸ì œ {q['id']}: {q['question']}\n"
                            questions_text += "\n".join(q['choices']) + "\n\n"
                        
                        answer_params = {
                            "passages": passages_text,
                            "sentences": sentences_text,
                            "questions": questions_text
                        }
                        
                        answer_response = generate_content_with_prompt("answer", **answer_params)
                        
                        if answer_response and "ì˜¤ë¥˜ ë°œìƒ" not in answer_response:
                            json_match = re.search(r'```json\s*(\{.*?\})\s*```', answer_response, re.DOTALL)
                            if json_match:
                                answer_data = json.loads(json_match.group(1))
                                result['answers'] = answer_data.get("answers", [])
        
        print("========== ì½˜í…ì¸  ìƒì„± ì™„ë£Œ ==========")
        return result
        
    except Exception as e:
        print(f"ì½˜í…ì¸  ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {"error": str(e)}

def run_test_scenario():
    """ì—”ë“œíˆ¬ì—”ë“œ í”„ë¡¬í”„íŠ¸ ìƒì„± ë° LLM í˜¸ì¶œ í…ŒìŠ¤íŠ¸"""
    print("========== 1. ì§€ë¬¸ ë° ì˜ˆë¬¸ ìƒì„± í…ŒìŠ¤íŠ¸ ì‹œì‘ ==========")
    
    # 1. ì§€ë¬¸ ë° ì˜ˆë¬¸ ìƒì„±
    passage_params = {
        "level": "ì¤‘í•™êµ 1í•™ë…„",
        "passage_count": "2",
        "passage_length": "80",
        "sentence_count": "3", 
        "sentence_length": "12",
        "word_list": "student, study, school, teacher, future, dream, important, help",
        "grammar_point": "toë¶€ì •ì‚¬ì˜ ëª…ì‚¬ì  ìš©ë²• (ì£¼ì–´, ëª©ì ì–´, ë³´ì–´)",
        "reading_type": "ì£¼ì œ/ì œëª© ì¶”ë¡ , ì„¸ë¶€ì‚¬í•­ íŒŒì•…",
        "topic": "í•™êµ ìƒí™œê³¼ ì¥ë˜ í¬ë§"
    }
    
    passage_response_str = generate_content_with_prompt("passage", **passage_params)
    print("--- [AI ì‘ë‹µ ì›ë³¸ (ì§€ë¬¸)] ---")
    print(passage_response_str)
    
    if not passage_response_str or "ì˜¤ë¥˜ ë°œìƒ" in passage_response_str:
        print("\n[ì˜¤ë¥˜] ì§€ë¬¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return

    try:
        # ì‘ë‹µ ë¬¸ìì—´ì—ì„œ JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', passage_response_str, re.DOTALL)
        if json_match:
            passage_json_str = json_match.group(1)
        else:
            # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ì´ ì—†ëŠ” ê²½ìš° ì „ì²´ë¥¼ JSONìœ¼ë¡œ ì‹œë„
            passage_json_str = passage_response_str.strip()
        
        passage_data = json.loads(passage_json_str)
        passages = passage_data.get("passages", [])
        sentences = passage_data.get("sentences", [])
        if not passages or not sentences:
            raise ValueError("JSON ì‘ë‹µì—ì„œ 'passages' ë˜ëŠ” 'sentences'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except (json.JSONDecodeError, ValueError) as e:
        print(f"\n[ì˜¤ë¥˜] ì§€ë¬¸ ì‘ë‹µ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        print("íŒŒì‹±ì— ì‹¤íŒ¨í•˜ì—¬ í…ŒìŠ¤íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    except Exception as e:
        print(f"\n[ì˜¤ë¥˜] ì§€ë¬¸ ì²˜ë¦¬ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")
        return

    print("\n========== 2. ë¬¸ì œ ìƒì„± í…ŒìŠ¤íŠ¸ ì‹œì‘ ==========")

    # 2. ë¬¸ì œ ìƒì„± (ì§€ë¬¸ê³¼ ì˜ˆë¬¸ì„ ëª¨ë‘ í™œìš©)
    passages_text = "\n\n".join([f"ì§€ë¬¸ {i+1}: {p['title']}\n{p['content']}" for i, p in enumerate(passages)])
    sentences_text = "\n".join([f"ì˜ˆë¬¸ {i+1}: {s['english']}" for i, s in enumerate(sentences)])
    
    question_params = {
        "passages": passages_text,
        "sentences": sentences_text,
        "question_count": "3",
        "question_type": "ê°ê´€ì‹ 4ì§€ì„ ë‹¤",
        "learning_objective": "ì§€ë¬¸ê³¼ ì˜ˆë¬¸ì„ í†µí•´ ì£¼ì œ íŒŒì•…, ì„¸ë¶€ì‚¬í•­ ì´í•´, ë¬¸ë²• ì ìš© ëŠ¥ë ¥ í‰ê°€"
    }

    question_response_str = generate_content_with_prompt("question", **question_params)
    print("--- [AI ì‘ë‹µ ì›ë³¸ (ë¬¸ì œ)] ---")
    print(question_response_str)

    if not question_response_str or "ì˜¤ë¥˜ ë°œìƒ" in question_response_str:
        print("\n[ì˜¤ë¥˜] ë¬¸ì œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return

    try:
        # ì‘ë‹µ ë¬¸ìì—´ì—ì„œ JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', question_response_str, re.DOTALL)
        if json_match:
            question_json_str = json_match.group(1)
        else:
            # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ì´ ì—†ëŠ” ê²½ìš° ì „ì²´ë¥¼ JSONìœ¼ë¡œ ì‹œë„
            question_json_str = question_response_str.strip()
        
        question_data = json.loads(question_json_str)
        questions = question_data.get("questions", [])
        if not questions:
             raise ValueError("JSON ì‘ë‹µì—ì„œ 'questions'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except (json.JSONDecodeError, ValueError) as e:
        print(f"\n[ì˜¤ë¥˜] ë¬¸ì œ ì‘ë‹µ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        return
    except Exception as e:
        print(f"\n[ì˜¤ë¥˜] ë¬¸ì œ ì²˜ë¦¬ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")
        return

    print("\n========== 3. ë‹µì•ˆ ìƒì„± í…ŒìŠ¤íŠ¸ ì‹œì‘ ==========")

    # 3. ë‹µì•ˆ ìƒì„± (ëª¨ë“  ë¬¸ì œë¥¼ í•œ ë²ˆì— ì±„ì )
    questions_text = ""
    for q in questions:
        questions_text += f"ë¬¸ì œ {q['id']}: {q['question']}\n"
        questions_text += "\n".join(q['choices']) + "\n\n"
    
    answer_params = {
        "passages": passages_text,
        "sentences": sentences_text,
        "questions": questions_text
    }

    answer_response_str = generate_content_with_prompt("answer", **answer_params)
    print("--- [AI ì‘ë‹µ ì›ë³¸ (ë‹µì•ˆ)] ---")
    print(answer_response_str)
    
    print("\n========== í…ŒìŠ¤íŠ¸ ì¢…ë£Œ ==========")

def test_scenario_3_detailed():
    """í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ 3ì„ ìƒì„¸í•˜ê²Œ ì‹¤í–‰í•˜ê³  ê° ë‹¨ê³„ë³„ ê²°ê³¼ë¥¼ ì¶œë ¥"""
    print("========== í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ 3 ìƒì„¸ ì‹¤í–‰ ==========")
    print("ë¬¸ë²• + ë…í•´ + ì–´íœ˜ (ê³ ê¸‰ ë‚œì´ë„)")
    print("í•™ë…„: ì¤‘í•™êµ 3í•™ë…„")
    print("ë¬¸ë²• ì†Œë¶„ë¥˜: í˜„ì¬ì™„ë£Œì‹œì œ, ê´€ê³„ëŒ€ëª…ì‚¬")
    print("=" * 60)
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
    print("\nğŸ”— ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¤‘...")
    db_manager = setup_database()
    
    if not db_manager:
        print("âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨ë¡œ í…ŒìŠ¤íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    print("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ")
    
    # 1. ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì •ë³´ ì¡°íšŒ
    print("\nğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì •ë³´ ì¡°íšŒ ì¤‘...")
    categories = ["ë¬¸ë²•", "ë…í•´", "ì–´íœ˜"]
    difficulty = "ê³ ê¸‰"
    grammar_subcategories = ["í˜„ì¬ì™„ë£Œì‹œì œ", "ê´€ê³„ëŒ€ëª…ì‚¬"]
    
    db_info = gather_db_info(db_manager, categories, difficulty, grammar_subcategories)
    
    print(f"  - ë¬¸ë²• í¬ì¸íŠ¸: {db_info['grammar_points']}")
    print(f"  - ë…í•´ ìœ í˜•: {db_info['reading_types']}")
    print(f"  - ì–´íœ˜ ì •ë³´: {db_info['vocabulary_info']}")
    print(f"  - ë‹¨ì–´ ëª©ë¡ (ì¼ë¶€): {db_info['word_list'][:10]}")
    
    # 2. í”„ë¡¬í”„íŠ¸ ë§¤ê°œë³€ìˆ˜ ìƒì„±
    print("\nâš™ï¸ í”„ë¡¬í”„íŠ¸ ë§¤ê°œë³€ìˆ˜ ìƒì„± ì¤‘...")
    prompt_params = build_prompt_params("ì¤‘í•™êµ 3í•™ë…„", categories, difficulty, db_info)
    
    print("  ìƒì„±ëœ ë§¤ê°œë³€ìˆ˜:")
    for key, value in prompt_params.items():
        print(f"    {key}: {value}")
    
    # 3. ì§€ë¬¸ ë° ì˜ˆë¬¸ ìƒì„±
    print("\nğŸ“ ì§€ë¬¸ ë° ì˜ˆë¬¸ ìƒì„± ì¤‘...")
    passage_response = generate_content_with_prompt("passage", **prompt_params)
    
    print("--- [AI ì‘ë‹µ ì›ë³¸ (ì§€ë¬¸ ë° ì˜ˆë¬¸)] ---")
    print(passage_response)
    print("-" * 50)
    
    if not passage_response or "ì˜¤ë¥˜ ë°œìƒ" in passage_response:
        print("âŒ ì§€ë¬¸ ìƒì„± ì‹¤íŒ¨")
        return
    
    # JSON íŒŒì‹±
    try:
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', passage_response, re.DOTALL)
        if json_match:
            passage_data = json.loads(json_match.group(1))
            passages = passage_data.get("passages", [])
            sentences = passage_data.get("sentences", [])
            
            print(f"âœ… ì§€ë¬¸ ë° ì˜ˆë¬¸ ìƒì„± ì„±ê³µ: ì§€ë¬¸ {len(passages)}ê°œ, ì˜ˆë¬¸ {len(sentences)}ê°œ")
            
            # ìƒì„±ëœ ì§€ë¬¸ê³¼ ì˜ˆë¬¸ ì¶œë ¥
            for i, passage in enumerate(passages):
                print(f"\nğŸ“– ì§€ë¬¸ {i+1}: {passage['title']}")
                print(f"   ë‚´ìš©: {passage['content']}")
                print(f"   ë²ˆì—­: {passage['korean_translation']}")
            
            for i, sentence in enumerate(sentences):
                print(f"\nğŸ’¬ ì˜ˆë¬¸ {i+1}: {sentence['english']}")
                print(f"   ë²ˆì—­: {sentence['korean']}")
        else:
            print("âŒ JSON íŒŒì‹± ì‹¤íŒ¨")
            return
    except Exception as e:
        print(f"âŒ ì§€ë¬¸ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
        return
    
    # 4. ë¬¸ì œ ìƒì„±
    print("\nâ“ ë¬¸ì œ ìƒì„± ì¤‘...")
    passages_text = "\n\n".join([f"ì§€ë¬¸ {i+1}: {p['title']}\n{p['content']}" for i, p in enumerate(passages)])
    sentences_text = "\n".join([f"ì˜ˆë¬¸ {i+1}: {s['english']}" for i, s in enumerate(sentences)])
    
    question_params = {
        "passages": passages_text,
        "sentences": sentences_text,
        "question_count": prompt_params.get("question_count", "4"),
        "question_type": "ê°ê´€ì‹ 4ì§€ì„ ë‹¤",
        "learning_objective": f"{prompt_params.get('reading_type', 'ë…í•´')} ë° {prompt_params.get('grammar_point', 'ë¬¸ë²•')} ì´í•´ í‰ê°€"
    }
    
    question_response = generate_content_with_prompt("question", **question_params)
    
    print("--- [AI ì‘ë‹µ ì›ë³¸ (ë¬¸ì œ)] ---")
    print(question_response)
    print("-" * 50)
    
    if not question_response or "ì˜¤ë¥˜ ë°œìƒ" in question_response:
        print("âŒ ë¬¸ì œ ìƒì„± ì‹¤íŒ¨")
        return
    
    # ë¬¸ì œ JSON íŒŒì‹±
    try:
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', question_response, re.DOTALL)
        if json_match:
            question_data = json.loads(json_match.group(1))
            questions = question_data.get("questions", [])
            
            print(f"âœ… ë¬¸ì œ ìƒì„± ì„±ê³µ: {len(questions)}ê°œ")
            
            # ìƒì„±ëœ ë¬¸ì œ ì¶œë ¥
            for i, q in enumerate(questions):
                print(f"\nğŸ” ë¬¸ì œ {q['id']}: {q['question']}")
                
                # ë³€í˜•ëœ ì§€ë¬¸ì´ ìˆëŠ” ê²½ìš° ì¶œë ¥
                if 'modified_passage' in q and q['modified_passage']:
                    print(f"   ğŸ“ ë³€í˜•ëœ ì§€ë¬¸: {q['modified_passage']}")
                
                # ë³€í˜• ìœ í˜• ì¶œë ¥
                if 'modification_type' in q:
                    print(f"   ğŸ”§ ë³€í˜• ìœ í˜•: {q['modification_type']}")
                
                for choice in q['choices']:
                    print(f"     {choice}")
                print(f"   ì¶œì²˜: {q.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
        else:
            print("âŒ ë¬¸ì œ JSON íŒŒì‹± ì‹¤íŒ¨")
            return
    except Exception as e:
        print(f"âŒ ë¬¸ì œ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
        return
    
    # 5. ë‹µì•ˆ ìƒì„±
    print("\nâœ… ë‹µì•ˆ ìƒì„± ì¤‘...")
    questions_text = ""
    for q in questions:
        questions_text += f"ë¬¸ì œ {q['id']}: {q['question']}\n"
        
        # ë³€í˜•ëœ ì§€ë¬¸ì´ ìˆëŠ” ê²½ìš° í¬í•¨
        if 'modified_passage' in q and q['modified_passage']:
            questions_text += f"ë³€í˜•ëœ ì§€ë¬¸: {q['modified_passage']}\n"
        
        # ë³€í˜• ìœ í˜• ì •ë³´ í¬í•¨
        if 'modification_type' in q:
            questions_text += f"ë³€í˜• ìœ í˜•: {q['modification_type']}\n"
        
        questions_text += "\n".join(q['choices']) + "\n\n"
    
    answer_params = {
        "passages": passages_text,
        "sentences": sentences_text,
        "questions": questions_text
    }
    
    answer_response = generate_content_with_prompt("answer", **answer_params)
    
    print("--- [AI ì‘ë‹µ ì›ë³¸ (ë‹µì•ˆ)] ---")
    print(answer_response)
    print("-" * 50)
    
    if answer_response and "ì˜¤ë¥˜ ë°œìƒ" not in answer_response:
        try:
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', answer_response, re.DOTALL)
            if json_match:
                answer_data = json.loads(json_match.group(1))
                answers = answer_data.get("answers", [])
                
                print(f"âœ… ë‹µì•ˆ ìƒì„± ì„±ê³µ: {len(answers)}ê°œ")
                
                # ìƒì„±ëœ ë‹µì•ˆ ì¶œë ¥
                for answer in answers:
                    print(f"\nğŸ¯ ë¬¸ì œ {answer['question_id']} ì •ë‹µ: {answer['correct_choice']}")
                    print(f"   í•´ì„¤: {answer['explanation']['main'][:100]}...")
                    print(f"   í•™ìŠµí¬ì¸íŠ¸: {answer['explanation']['learning_point'][:100]}...")
            else:
                print("âŒ ë‹µì•ˆ JSON íŒŒì‹± ì‹¤íŒ¨")
        except Exception as e:
            print(f"âŒ ë‹µì•ˆ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
    else:
        print("âŒ ë‹µì•ˆ ìƒì„± ì‹¤íŒ¨")
    
    print("\nğŸ‰ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ 3 ì™„ë£Œ!")
    print("=" * 60)

def test_new_structure():
    """ìƒˆë¡œìš´ ì…ë ¥ êµ¬ì¡°ë¥¼ í…ŒìŠ¤íŠ¸í•˜ëŠ” í•¨ìˆ˜"""
    print("========== ìƒˆë¡œìš´ ì…ë ¥ êµ¬ì¡° í…ŒìŠ¤íŠ¸ ì‹œì‘ ==========")
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
    db_manager = setup_database()
    
    if not db_manager:
        print("âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨ë¡œ í…ŒìŠ¤íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    # í…ŒìŠ¤íŠ¸ ìš”ì²­ ë°ì´í„° êµ¬ì„±
    test_request = {
        "grade": 2,
        "categories": [
            {
                "name": "ë…í•´",
                "subcategories": ["ì£¼ì œ/ì œëª© ì¶”ë¡ ", "ì„¸ë¶€ì‚¬í•­ íŒŒì•…"],
                "ratio": 50
            },
            {
                "name": "ë¬¸ë²•", 
                "subcategories": ["í˜„ì¬ì™„ë£Œì‹œì œ", "ê´€ê³„ëŒ€ëª…ì‚¬"],
                "ratio": 30
            },
            {
                "name": "ì–´íœ˜",
                "subcategories": ["ë¬¸ë§¥ìƒ ì ì ˆí•œ ì–´íœ˜"],
                "ratio": 20
            }
        ],
        "question_type": "ê°ê´€ì‹",
        "difficulty": "ë¶„ë°°",
        "difficulty_distribution": {
            "high": 20,    # ìƒ
            "medium": 60,  # ì¤‘
            "low": 20      # í•˜
        },
        "total_questions": 10
    }
    
    print("\nğŸ“‹ í…ŒìŠ¤íŠ¸ ìš”ì²­ ë°ì´í„°:")
    print(f"  í•™ë…„: {test_request['grade']}í•™ë…„")
    print(f"  ë¬¸ì œ ìœ í˜•: {test_request['question_type']}")
    print(f"  ë‚œì´ë„: {test_request['difficulty']}")
    print(f"  ì´ ë¬¸í•­: {test_request['total_questions']}ê°œ")
    print("  ì¹´í…Œê³ ë¦¬ êµ¬ì„±:")
    for cat in test_request['categories']:
        print(f"    - {cat['name']} ({cat['ratio']}%): {', '.join(cat['subcategories'])}")
    print(f"  ë‚œì´ë„ ë¶„ë°°: ìƒ({test_request['difficulty_distribution']['high']}%) ì¤‘({test_request['difficulty_distribution']['medium']}%) í•˜({test_request['difficulty_distribution']['low']}%)")
    
    # ìƒˆë¡œìš´ êµ¬ì¡°ë¡œ ì½˜í…ì¸  ìƒì„±
    try:
        result = process_user_request_new(db_manager, test_request)
        
        if result and 'error' not in result:
            print(f"\nğŸ‰ ìƒˆë¡œìš´ êµ¬ì¡° í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
            print(f"  ğŸ“– ìƒì„±ëœ ì§€ë¬¸: {len(result.get('passages', []))}ê°œ")
            print(f"  ğŸ’¬ ìƒì„±ëœ ì˜ˆë¬¸: {len(result.get('sentences', []))}ê°œ") 
            print(f"  â“ ìƒì„±ëœ ë¬¸ì œ: {len(result.get('questions', []))}ê°œ")
            print(f"  âœ… ìƒì„±ëœ ë‹µì•ˆ: {len(result.get('answers', []))}ê°œ")
            
            # ìƒì„±ëœ ì§€ë¬¸ ìš”ì•½ ì¶œë ¥
            print(f"\nğŸ“š ìƒì„±ëœ ì§€ë¬¸ ìš”ì•½:")
            for i, passage in enumerate(result.get('passages', [])):
                print(f"  {i+1}. {passage.get('title', 'ì œëª© ì—†ìŒ')} [{passage.get('distribution_info', 'ì •ë³´ ì—†ìŒ')}]")
            
            # ìƒì„±ëœ ë¬¸ì œ ìš”ì•½ ì¶œë ¥
            print(f"\nğŸ” ìƒì„±ëœ ë¬¸ì œ ìš”ì•½:")
            for i, question in enumerate(result.get('questions', [])):
                print(f"  {question.get('id', i+1)}. {question.get('question', 'ì§ˆë¬¸ ì—†ìŒ')[:50]}...")
                if 'modification_type' in question:
                    print(f"      ë³€í˜• ìœ í˜•: {question['modification_type']}")
            
        else:
            print(f"âŒ ìƒˆë¡œìš´ êµ¬ì¡° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
            
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    print("\n========== ìƒˆë¡œìš´ ì…ë ¥ êµ¬ì¡° í…ŒìŠ¤íŠ¸ ì™„ë£Œ ==========")

# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    # API í‚¤ê°€ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸
    if not os.getenv('GEMINI_API_KEY'):
        print("GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    else:
        print("ìƒˆë¡œìš´ ì…ë ¥ êµ¬ì¡°ë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
        test_new_structure()
        
        # ê¸°ì¡´ í…ŒìŠ¤íŠ¸ë„ ì‹¤í–‰í•˜ê³  ì‹¶ë‹¤ë©´ ì£¼ì„ í•´ì œ
        # print("\nê¸°ì¡´ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ë„ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        # test_scenario_3_detailed()
